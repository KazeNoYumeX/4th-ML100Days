# 4th-ML100Days

### 機器學習概論 Introduction of Machine Learning
##### 1. 機器學習概論 
* 從概念上理解機器學習的目的與限制，並導覽機器學習流程
```
Day_01 : 資料介紹與評估資料
Day_02 : 機器學習概論
Day_03 : 機器學習 - 流程與步驟
Day_04 : EDA/讀取資料與分析流程
```
* **Day_05 : 如何建立一個 DataFrame？如何讀取其他資料？**
* **Day_06 : 欄位的資料類型介紹及處理**
* **Day_07 : 特徵類型**
* **Day_08 : EDA 之資料分佈**
* **Day_09 : 離群值 (Outlier) 及其處理**
* **Day_10 : 數值特徵 - 去除離群值**
* **Day_11 : 數值填補與連續數值標準化**
* **Day_12 : 數值型特徵 - 補缺失值與標準化**
* **Day_13 : 常用的 DataFrame 操作**
* **Day_14 : 相關係數簡介**
* **Day_15 : 相關係數實作**
* **Day_16 : 繪圖與樣式 ＆ Kernel Density Estimation (KDE)**
* **Day_17 : 把連續型變數離散化**
* **Day_18 : 把連續型變數離散化實作**
* **Day_19 : Subplot**
* **Day_20 : Heatmap & Grid-plot**
* **Day_21 : 模型初體驗 - Logistic Regression**
* **Day_22 : 特徵工程簡介**
* **Day_23 : 數值型特徵 - 去除偏態**
* **Day_24 : 類別型特徵 - 基礎處理**
* **Day_25 : 類別型特徵 - 均值編碼**
* **Day_26 : 類別型特徵 - 其他進階處理**
* **Day_27 : 時間型特徵**
* **Day_28 : 特徵組合 - 數值與數值組合**
* **Day_29 : 特徵組合 - 類別與數值組合**
* **Day_30 : 特徵選擇**
* **Day_31 : 特徵評估**
* **Day_32 : 分類型特徵優化 - 葉編碼**
* **Day_33 : 機器如何學習**
* **Day_34 : 訓練與測試集切分**
* **Day_35 : Regression & Classification**
* **Day_36 : 評估指標選定**
* **Day_37 : Regression 模型**
* **Day_38 : Regression 模型 </>**
* **Day_39 : LASSO, Ridge regression**
* **Day_40 : LASSO, Ridge regression </>**
* **Day_41 : 決策樹 Decision Tree**
* **Day_42 : 決策樹 </>**
* **Day_43 : 隨機森林樹 Random Forest**
* **Day_44 : 隨機森林樹 </>**
* **Day_45 : 梯度提升機 Gradient Boosting Machine**
* **Day_46 : 梯度提升機 </>**
* **Day_47 : 超參數調整**
* **Day_48 : Kaggle**
* **Day_49 : 混和泛化 (Blending)**
* **Day_50 : 堆疊泛化 (Stacking)**
* **Day_51~53 : Kaggle期中考**
* **Day_54 : 非監督式機器學習簡介**
* **Day_55 : K-means 聚類算法**
* **Day_56 : K-means 觀察 : 使用輪廓分析**
* **Day_57 : 階層分群法**
* **Day_58 : 階層分群法 觀察 : 2D 樣版資料集**
* **Day_59 : 降維方法 - 主成分分析**
* **Day_60 : PCA 觀察 : 使用手寫辨識資料集**
* **Day_61 : 降維方法 - t-SNE**
* **Day_62 : t-sne 觀察 : 分群與流形還原**
* **Day_63 : 深度學習簡介**
* **Day_64 : 深度學習體驗 - 模型調整與學習曲線**
* **Day_65 : 深度學習體驗 - 啟動函數與正規化**
* **Day_66 : Keras 安裝與介紹**
* **Day_67 : Keras embedded dataset 的介紹與應用**
* **Day_68 : 序列模型搭建網路 Sequential API**
* **Day_69 : Keras Module API 的介紹與應用**
* **Day_70 : Multi-layer Perception 簡介**
* **Day_71 : 損失函數的介紹與應用**
* **Day_72 : 啟動函數的介紹與應用**
* **Day_73 : 梯度下降 Gradient Descent 簡介**
* **Day_74 : Gradient Descent 數學原理**
* **Day_75 : 反向式傳播簡介**
* **Day_76 : 優化器 Optimizers 簡介**
* **Day_77 : 訓練神經網路的細節與技巧**
* **Day_78 : 訓練神經網路前的注意事項**
* **Day_79 : 訓練神經網路的細節與技巧 - Learning Rate Effect**
* **Day_80 : 優化器與學習率的組合與比較**
* **Day_81 : 訓練神經網路的細節與技巧 - Regularization**
* **Day_82 : 訓練神經網路的細節與技巧 - Dropout**
* **Day_83 : 訓練神經網路的細節與技巧 - Batch normalization**
* **Day_84 : 正規化/機移除/批次標準化的 組合與比較**
* **Day_85 : 訓練神經網路的細節與技巧 - 使用 callbacks 函數做 earlystop**
* **Day_86 : 訓練神經網路的細節與技巧 - 使用 callbacks 函數儲存 model**
* **Day_87 : 訓練神經網路的細節與技巧 - 使用 callbacks 函數做 reduce learning rate**
* **Day_88 : 訓練神經網路的細節與技巧 - 撰寫自己的 callbacks 函數**
* **Day_89 : 訓練神經網路的細節與技巧 - 撰寫自己的 Loss function**
* **Day_90 : 傳統電腦視覺與影像辨識**
* **Day_91 : 傳統電腦視覺與影像辨識 </>**
* **Day_92 : 卷積神經網路(Convolution Neural Network, CNN) 簡介**
* **Day_93 : 卷積神經網路架構細節**
* **Day_94 : 卷積神經網路 - 卷積(Convolution)層與參數調整**
* **Day_95 : 卷積神經網路 - 池化(Pooling)層與參數調整**
* **Day_96 : Keras 中的 CNN layers**
* **Day_97 : 使用 CNN 完成 CIFAR-10 資料集 </>**
* **Day_98 : 訓練卷積神經網路的細節與技巧 - 處理大量數據**
* **Day_99 : 訓練卷積神經網路的細節與技巧 - 處理小量數據**
* **Day_100 : 訓練卷積神經網路的細節與技巧 - 轉移學習 (Transfer learning)**
* **Day_101~103 : 影像辨識**
* **Day_104 : 互動式網頁神經網路視覺化**
* **Day_105 : CNN 卷積網路演進和應用**
* **Day_106 : 電腦視覺常用公開資料集**
* **Day_107 : 電腦視覺應用介紹 - 影像分類, 影像分割, 物件偵測**